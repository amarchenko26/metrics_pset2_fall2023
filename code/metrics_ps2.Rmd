---
title: "Applied Metrics Empirical P-Set 2, Fall 2023"
output: pdf_document
date: "2023-11-29"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, tidy.opts=list(width.cutoff=60), tidy=TRUE)
```

### Load data

```{r }
# Clear all
rm(list = ls())

# load and require packages
pacman::p_load(foreign, tidyverse, here, randomForest, boot, MASS)

# Load data
data <- read.csv(here("data/andres_cleaned.csv"))
data$X <- NULL

set.seed(1234) # For reproducibility


```

### Question 1a - Relate structural equation and probit regression

Suppose we specify the potential outcome equations as $Y_i(1) = X'_i \theta_1 + \epsilon_{1i}$ and $Y_i(0) = X'_i \theta_0 + \epsilon_{0i}$, and the structural selection equation as $D_i = 1 \{u(X_i,Z_i) \geq V_i \}$. where $u(X_i,Z_i) - V_i$ is the latent utility derived from additional children.

The structural selection equation describes the switch from $D = 0$ to $D=1$ in terms of utility, i.e., whether, as a function of your observables and instrument, the family has a higher utility than some level of having more than three children. The propensity score quantifies this probability, capturing the likelihood, given your observables and instrument value, of having $D = 1$.

### Question 1b - Assumptions for MTE

Clarify a set of assumptions that the marginal treatment effect $M(x,u)$, $u \in (0,1)$ can be identified by the derivative of the OLS regression equation WRT the propensity score: $$MTE(x, u) = \frac{\partial}{\partial p}\bigg|_{p=u} \left( x'\beta_0 + px'\beta_1 + \kappa_1p + \kappa_2p^2 + \kappa_3p^3 \right)$$

The assumptions are: XXXXX

### Question 1c - Estimate propensity score

Estimate the propensity score as instructed above, and assess whether the coefficient of the instrumental variable in the probit regression is significantly different from zero or not.

Yes, we see that the z-value for the instrument is extremely large at 37, and very significant. So we have confidence that the instrument is predicting treatment.

```{r }
# Fit probit
probit_model <- glm(d ~ blackm + hispm + othracem + agem1 + agefstm + boy1st + z, 
                    data = data, 
                    family = binomial(link = "probit"))

# Predict propensity scores
data$prop_score <- predict(probit_model, type = "response")

summary(probit_model)
```

### Question 1d - Plot histogram of estimated propensity scores

```{r }
hist(data$prop_score, 
     main = "Histogram of Estimated Propensity Scores", 
     xlab = "Propensity Score", 
     ylab = "Frequency",
     col = "blue",
     border = "black")
```

```{r }
summary(probit_model)
```

### Question 1e - Estimate by OLS, bootstrap standard errors

Report the OLS estimates of the coefficients in the regression equation of (2) and their bootstrap standard errors with 1000 bootstrap replications.

```{r }
# Fit OLS
ols <- lm(y ~ blackm + hispm + othracem + agem1 + agefstm + boy1st + 
            prop_score*(blackm + hispm + othracem + agem1 + agefstm + boy1st) + 
            prop_score + I(prop_score^2) + I(prop_score^3), 
                    data = data)

summary(ols)

# Function to fit model on bootstrap sample
boot_fn <- function(data, index) {
  fit <- lm(y ~ blackm + hispm + othracem + agem1 + agefstm + boy1st + 
            prop_score*(blackm + hispm + othracem + agem1 + agefstm + boy1st) + 
            prop_score + I(prop_score^2) + I(prop_score^3), 
            data = data, subset = index)
  return(coef(fit))
}

# Perform bootstrap
boot_results <- boot(data, boot_fn, R = 1000)

# Calculate standard errors
boot_se <- apply(boot_results$t, 2, sd)
```

### Question 1f - Calculate MTE and their CI

Plot the MTE estimates (as a function of u âˆˆ [0,1]) and pointwise confidence intervals,
holding X constant at its sample mean values. The confidence intervals are constructed
using the boostrap results.

```{r}

# Step 1: Calculate the means of the covariates
covariate_means <- colMeans(data[, c("blackm", "hispm", "othracem", "agem1", "agefstm", "boy1st")], na.rm = TRUE)

# Calculate the first term of the derivative (x prime times beta1)
beta1 <- coef(ols)[11:16]
xprime <- matrix(covariate_means, nrow = 1, ncol = 6) #transpose to make 1x6
beta1 <- matrix(beta1, nrow = 6, ncol = 1) #transpose to make 6x1
xbeta1 <- xprime %*% beta1

kappa1 <- coef(ols)[8] #prop_score coef
kappa2 <- coef(ols)[9] #prop_score^2 coef
kappa3 <- coef(ols)[10] #prop_score^3 coef

marginal_effects <- as.vector(xbeta1) + as.vector(kappa1) + (2 * as.vector(kappa2) * data$prop_score) + (3 * as.vector(kappa3) * (data$prop_score)^2)

x_axis <- sort(data$prop_score)

# Create a new data frame for plotting
plot_data <- data.frame(xvar = sort(data$prop_score), marginal_effects = marginal_effects)

# Use ggplot to create the scatterplot
ggplot(plot_data, aes(x = xvar, y = marginal_effects)) +
  geom_point() +
  theme_minimal() +
  labs(x = "u", y = "Marginal Effects", 
       title = "Scatterplot of Marginal Effects vs. Unobserved Heterogeneity u")


#m0 and m1 are formulas specifying the MTR functions for the untreated and treated arms, respectively. The symbol u in the formula refers to the unobservable latent variable in the selection equation.
#ivlike indicates the regressions to be run to create moments to which the model is fit.

mte <- ivmte(data = data,
           target = "att",
           m0 = ~ u + blackm + hispm + othracem + agem1 + agefstm + boy1st,
           m1 = ~ u + blackm + hispm + othracem + agem1 + agefstm + boy1st,
           ivlike = c(y ~ d),
           propensity = d ~ blackm + hispm + othracem + agem1 + agefstm + boy1st + z,
#           bootstraps = 50, 
           link = "probit")

mte$bounds.ci

```

### Question 1g - Interpret

Based on the presented estimates, interpret heterogeneity of the marginal treatment effects.
What type of parent has a larger causal effect than others? In your answer, be explicit
about how to interpret u.

In this case, the marginal treatment effect is the difference betewen the marginal treatment response functions of treated and untreated individuals, conditional on \$U = u\$ and \$X_i = x\$. $u$ is the unobservable latent variable in the selection equation. That is, \$u\$ captures the unobservable propensity to take up treatment. The monotonicity assumption allows us to order individuals in a one-dimensional manner according to their latent propensity to take up treatment.

If MTE is declining in \$u\$, that means that people who are less likely to choose treatment experience smaller treatment effects than those who are more likely to choose treatment.

QUESTION - is it that $u$ is the unobservable heterogeneity ehre?

### Question 2 -

```{r}

```

### Question 2 

```{r}
set.seed(1234)

# Set the number of variables and observations
n_vars <- 20
n_obs <- 500

# Create the variance matrix sigma
sigma <- matrix(0, nrow = n_vars, ncol = n_vars)
for (i in 1:n_vars) {
  for (j in 1:n_vars) {
    sigma[i, j] <- 0.8^abs(j - i)
  }
}

# Ensure diagonal entries are 1
diag(sigma) <- 1

# Generate the data
data2 <- as.data.frame(mvrnorm(n = n_obs, mu = rep(0, n_vars), Sigma = sigma)) # Need MASS package

###################################

# Set up
a0 <- 1
a1 <- 0.25
b0 <- 1
b1 <- 0.25
tau <- 0.5

# Define m and V
m <- function(X1, X3){
    return(a0*X1 + a1*(exp(X3)/(1+exp(X3))))
}

V_fun <- function(X1, X3){
  zeta <- rnorm(500,0,1)
  return(m(X1, X3) + zeta)
}

V <- V_fun(data2$V1, data2$V3)
data2$D <- ifelse(V > 0, 1, 0)

# Define g(X,D) and Y
g_fun <- function(D, X1, X3){
    return(tau*D + b0*(exp(X1)/(1+exp(X1))) + b1*X3)
}

Y_fun <- function(X1, X3, D){
  epsilon <- rnorm(500, 0, 1)
  return(g(D, X1, X3) + epsilon)
}

data2$Y <- Y_fun(data2$V1, data2$V3, data2$D)

###################################

independent_vars <- paste0("V", 1:20, collapse = " + ")
formula <- as.formula(paste("D ~ ", independent_vars))

# Fit probit
probit_model <- glm(formula, 
                    data = data2, 
                    family = binomial(link = "probit"))

# Predict propensity scores
data2$prop_score <- predict(probit_model, type = "response")

summary(probit_model)

data2$w_ate <- (data2$D * data2$Y/(data2[["prop_score"]])) - ((1-data2$D) * data2$Y/(1-data2[["prop_score"]]))

ate_probit <- mean(data2$w_ate)

```
